---
apiVersion: serving.kserve.io/v1alpha2
kind: LLMInferenceServiceConfig
metadata:
  name: llmisvc-intelligent-inference-scheduling
  namespace: kserve-lab
spec:
  template:
    containers:
      # This image avoids Error 803 (unsupported CUDA driver combination); see https://github.com/llm-d/llm-d/issues/706
      - image: ghcr.io/llm-d/llm-d-cuda-dev:sha-4f5cdd5
        imagePullPolicy: IfNotPresent
        name: main
        ports:
          - containerPort: 8000
            protocol: TCP
        command: ["/bin/sh", "-c"]
        args:
          - >
            vllm serve /mnt/models
            --served-model-name "{{ .Spec.Model.Name }}"
            --port 8000
            --disable-uvicorn-access-log
            --disable-log-requests
            $VLLM_ADDITIONAL_ARGS
        env:
          - name: HOME
            value: /home
          - name: VLLM_LOGGING_LEVEL
            value: INFO
          - name: HF_HUB_CACHE
            value: /models
        securityContext:
          allowPrivilegeEscalation: false
          readOnlyRootFilesystem: false
          runAsNonRoot: true
          capabilities:
            drop:
              - ALL
          seccompProfile:
            type: RuntimeDefault
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: FallbackToLogsOnError
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
            scheme: HTTP
          initialDelaySeconds: 4800
          periodSeconds: 10
          timeoutSeconds: 10
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /health
            port: 8000
            scheme: HTTP
          initialDelaySeconds: 10
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 60
        volumeMounts:
          - mountPath: /home
            name: home
          - mountPath: /dev/shm
            name: dshm
          - mountPath: /models
            name: model-cache
          - mountPath: /etc/ssl/certs
            name: tls-certs
            readOnly: true
    terminationGracePeriodSeconds: 30
    volumes:
      - emptyDir: { }
        name: home
      - emptyDir:
          medium: Memory
          sizeLimit: 1Gi
        name: dshm
      - emptyDir: { }
        name: model-cache
      - name: tls-certs
        secret:
          secretName: "{{ ChildName .ObjectMeta.Name `-kserve-self-signed-certs` }}"
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
            - matchExpressions:
                - key: kubernetes.io/hostname
                  operator: In
                  values:
                    - worker-gpu2
  router:
    scheduler:
      pool:
        spec:
          endpointPickerRef:
            failureMode: FailOpen
            group: ""
            kind: Service
            name: '{{ ChildName .ObjectMeta.Name `-epp-service` }}'
            port:
              number: 9002
          selector:
            matchLabels:
              app.kubernetes.io/name: '{{ .ObjectMeta.Name }}'
              app.kubernetes.io/part-of: llminferenceservice
              kserve.io/component: workload
          targetPorts:
          - number: 8000
      template:
        containers:
          - name: main
            ports:
              - containerPort: 9002
                name: grpc
                protocol: TCP
              - containerPort: 9003
                name: grpc-health
                protocol: TCP
              - containerPort: 9090
                name: metrics
                protocol: TCP
            image: ghcr.io/llm-d/llm-d-inference-scheduler:v0.5.0
            imagePullPolicy: IfNotPresent
            livenessProbe:
              failureThreshold: 3
              grpc:
                port: 9003
                service: envoy.service.ext_proc.v3.ExternalProcessor
              initialDelaySeconds: 5
              periodSeconds: 10
              successThreshold: 1
              timeoutSeconds: 1
            readinessProbe:
              failureThreshold: 3
              grpc:
                port: 9003
                service: envoy.service.ext_proc.v3.ExternalProcessor
              initialDelaySeconds: 30
              periodSeconds: 10
              successThreshold: 1
              timeoutSeconds: 1
            args:
              - --pool-name
              - '{{ ChildName .ObjectMeta.Name `-inference-pool` }}'
              - --pool-namespace
              - '{{ .ObjectMeta.Namespace }}'
              - --zap-encoder
              - json
              - --grpc-port
              - "9002"
              - --grpc-health-port
              - "9003"
              - --kv-cache-usage-percentage-metric
              - "vllm:kv_cache_usage_perc"
              - --metrics-endpoint-auth=false
              - --secure-serving
              - --cert-path
              - /etc/ssl/certs
        volumes:
          - name: tls-certs
            secret:
              secretName: "{{ ChildName .ObjectMeta.Name `-kserve-self-signed-certs` }}"
        affinity:
          nodeAffinity:
            requiredDuringSchedulingIgnoredDuringExecution:
              nodeSelectorTerms:
                - matchExpressions:
                    - key: kubernetes.io/hostname
                      operator: In
                      values:
                        - worker-gpu2
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        terminationGracePeriodSeconds: 30
