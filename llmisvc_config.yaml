---
apiVersion: serving.kserve.io/v1alpha2
kind: LLMInferenceServiceConfig
metadata:
  name: llmisvc-inf-scheduler
  namespace: kserve-lab
spec:
  template:
    containers:
      # This image avoids Error 803 (unsupported CUDA driver combination); see https://github.com/llm-d/llm-d/issues/706
      - image: ghcr.io/llm-d/llm-d-cuda-dev:sha-4f5cdd5
        imagePullPolicy: IfNotPresent
        name: main
        ports:
          - containerPort: 8000
            protocol: TCP
        command: ["/bin/sh", "-c"]
        args:
          - >
            vllm serve /mnt/models
            --served-model-name "{{ .Spec.Model.Name }}"
            --port 8000
            --disable-uvicorn-access-log
            --disable-log-requests
            --prefix-caching-hash-algo sha256_cbor
            --block-size 64
            --kv_transfer_config '{"kv_connector":"NixlConnector","kv_role":"kv_both"}'
            --kv-events-config "$KV_EVENTS_CONFIG"
            $VLLM_ADDITIONAL_ARGS
        env:
          - name: KV_EVENTS_CONFIG
            value: |
              {
                "enable_kv_cache_events": true,
                "publisher": "zmq",
                "endpoint": "tcp://{{ ChildName .ObjectMeta.Name `-epp-service` }}.{{ .ObjectMeta.Namespace }}.svc.cluster.local:5557",
                "topic": "kv@$(POD_IP)@{{ .Spec.Model.Name }}"
              }
          - name: POD_IP
            valueFrom:
              fieldRef:
                fieldPath: status.podIP
          - name: PYTHONHASHSEED
            value: "42"
          - name: HOME
            value: /home
          - name: VLLM_LOGGING_LEVEL
            value: INFO
          - name: HF_HUB_CACHE
            value: /models
        securityContext:
          allowPrivilegeEscalation: false
          readOnlyRootFilesystem: false
          runAsNonRoot: true
          capabilities:
            drop:
              - ALL
          seccompProfile:
            type: RuntimeDefault
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: FallbackToLogsOnError
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
            scheme: HTTP
          initialDelaySeconds: 4800
          periodSeconds: 10
          timeoutSeconds: 10
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /health
            port: 8000
            scheme: HTTP
          initialDelaySeconds: 10
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 60
        volumeMounts:
          - mountPath: /home
            name: home
          - mountPath: /dev/shm
            name: dshm
          - mountPath: /models
            name: model-cache
          - mountPath: /etc/ssl/certs
            name: tls-certs
            readOnly: true
    terminationGracePeriodSeconds: 30
    volumes:
      - emptyDir: { }
        name: home
      - emptyDir:
          medium: Memory
          sizeLimit: 1Gi
        name: dshm
      - emptyDir: { }
        name: model-cache
      - name: tls-certs
        secret:
          secretName: "{{ ChildName .ObjectMeta.Name `-kserve-self-signed-certs` }}"
  router:
    scheduler:
      pool:
        spec:
          endpointPickerRef:
            failureMode: FailOpen
            group: ""
            kind: Service
            name: '{{ ChildName .ObjectMeta.Name `-epp-service` }}'
            port:
              number: 9002
          selector:
            matchLabels:
              app.kubernetes.io/name: '{{ .ObjectMeta.Name }}'
              app.kubernetes.io/part-of: llminferenceservice
              kserve.io/component: workload
          targetPorts:
          - number: 8000
      template:
        containers:
          - name: main
            ports:
              - containerPort: 9002
                name: grpc
                protocol: TCP
              - containerPort: 9003
                name: grpc-health
                protocol: TCP
              - containerPort: 9090
                name: metrics
                protocol: TCP
            image: ghcr.io/llm-d/llm-d-inference-scheduler:v0.5.0
            imagePullPolicy: IfNotPresent
            env:
              - name: HF_HOME
                value: /mnt/tokenizers
              - name: TMPDIR
                value: /mnt/tokenizers
            livenessProbe:
              failureThreshold: 3
              grpc:
                port: 9003
                service: envoy.service.ext_proc.v3.ExternalProcessor
              initialDelaySeconds: 5
              periodSeconds: 10
              successThreshold: 1
              timeoutSeconds: 1
            readinessProbe:
              failureThreshold: 3
              grpc:
                port: 9003
                service: envoy.service.ext_proc.v3.ExternalProcessor
              initialDelaySeconds: 30
              periodSeconds: 10
              successThreshold: 1
              timeoutSeconds: 1
            args:
              - --pool-name
              - '{{ ChildName .ObjectMeta.Name `-inference-pool` }}'
              - --pool-namespace
              - '{{ .ObjectMeta.Namespace }}'
              - --zap-encoder
              - json
              - --grpc-port
              - "9002"
              - --grpc-health-port
              - "9003"
              - --secure-serving
              - --cert-path
              - /etc/ssl/certs
              - --metrics-endpoint-auth=false
              - --config-text
              - |
                apiVersion: inference.networking.x-k8s.io/v1alpha1
                kind: EndpointPickerConfig
                plugins:
                  - type: single-profile-handler
                  - type: precise-prefix-cache-scorer
                    parameters:
                      kvEventsConfig:
                        zmqEndpoint: "tcp://*:5557"
                      indexerConfig:
                        tokenProcessorConfig:
                          blockSize: 64
                          hashSeed: "42"
                        kvBlockIndexConfig:
                          enableMetrics: true
                          metricsLoggingInterval: 60000000000
                        tokenizersPoolConfig:
                          modelName: "{{ .Spec.Model.Name }}"
                          tokenizersCacheDir: "/mnt/tokenizers"
                  - type: queue-scorer
                  - type: kv-cache-utilization-scorer
                  - type: max-score-picker
                schedulingProfiles:
                  - name: default
                    plugins:
                      - pluginRef: queue-scorer
                        weight: 2
                      - pluginRef: kv-cache-utilization-scorer
                        weight: 2
                      - pluginRef: precise-prefix-cache-scorer
                        weight: 3
                      - pluginRef: max-score-picker
            resources:
              requests:
                cpu: 256m
                memory: 500Mi
            terminationMessagePath: /dev/termination-log
            terminationMessagePolicy: FallbackToLogsOnError
            securityContext:
              allowPrivilegeEscalation: false
              readOnlyRootFilesystem: true
              runAsNonRoot: true
              capabilities:
                drop:
                  - ALL
              seccompProfile:
                type: RuntimeDefault
            volumeMounts:
              - mountPath: /etc/ssl/certs
                name: tls-certs
                readOnly: true
              - mountPath: /mnt/tokenizers
                name: tokenizers
              - mountPath: /go
                name: go-cache
        volumes:
          - name: tls-certs
            secret:
              secretName: "{{ ChildName .ObjectMeta.Name `-kserve-self-signed-certs` }}"
          - name: tokenizers
            emptyDir: {}
          - name: go-cache
            emptyDir: {}
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        terminationGracePeriodSeconds: 30
